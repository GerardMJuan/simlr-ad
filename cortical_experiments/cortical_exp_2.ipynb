{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cortical structure experiments - 2\n",
    "\n",
    "This script performs permutation testing experiments on cortical structures betweeen diagnostic groups for each presentation.\n",
    "This script generates the necessary files to run the freesurfer glmfit -sim command, with permutation testing, and save the results, for later analysis and visualization.\n",
    "\n",
    "More info about the permutation procedure in freesurfer can be found in:\n",
    "https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/MultipleComparisonsV6.0Perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization and loading of variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the procedure\n",
    "clusters = 4\n",
    "rd_seed = 1714\n",
    "n_perm = 1000\n",
    "\n",
    "# thickness or volume\n",
    "mode = \"thickness\"\n",
    "DX = [('CN','AD'), ('CN', 'LMCI'), ('LMCI', 'AD')]\n",
    "C = [\"C1\", \"C2\", \"C3\", \"C4\"]\n",
    "\n",
    "# Path of the generated clusters, after a run of cimlr-ad.py\n",
    "cluster_path = \"/homedtic/gmarti/EXPERIMENTS/CIMLR-AD/cimlr4/\"      \n",
    "df_cluster = pd.read_csv(cluster_path + 'cluster_data.csv')\n",
    "df_cluster.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare files for the concrete problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of subjects\n",
    "fsid_names = [x for x in map(lambda s: 'ADNI' + s[0:3] + 'S' + s[6:], \n",
    "                             df_cluster.PTID.values)]\n",
    "\n",
    "# Support dataframe, with the info that we need to write\n",
    "df_qdec = pd.DataFrame(data={'fsid': fsid_names,\n",
    "                            'cluster': df_cluster.C.values,\n",
    "                            'diagnosis': df_cluster.DX.values},\n",
    "                       columns = ['fsid', 'cluster', 'diagnosis'])\n",
    "\n",
    "# We want to test the thickness in the population of each cluster\n",
    "# against the rest, so that we can observe differences across the \n",
    "# whole cluster.\n",
    "\n",
    "# Contrast: same for all the 4 experiments\n",
    "def write_contrast(name, matrix):\n",
    "    with open(name, 'w') as f:\n",
    "        f.write(matrix)  # First line, mandatory\n",
    "\n",
    "# Create a fsgd file for each of the tests.\n",
    "fsgd_files = []\n",
    "for d in DX:\n",
    "    for c in C:\n",
    "        # Create FSGD file\n",
    "        # Only write the subjects that \n",
    "        fsgd_file = 'freefiles/adni_files_ex2_' + c + '_' + d[0] + '_' + d[1] + '.fsgd'\n",
    "        fsgd_files.append(fsgd_file)\n",
    "        with open(fsgd_file, 'w') as f:\n",
    "            f.write('GroupDescriptorFile 1\\n')  # First line, mandatory\n",
    "            # Title, optional\n",
    "            f.write('Title ex2-c ' + c + ' ' + d[0] + 'vs' +  d[1] + '\\n')\n",
    "            # three classes, two corresponding to diagnosis and rest\n",
    "            # rest will not be considered for test, but need to be included\n",
    "            # for later testing\n",
    "            # rest will be CN and AD classes that are \n",
    "            f.write('Class ' + d[0] + '\\n')\n",
    "            f.write('Class ' + d[1] + '\\n')\n",
    "            f.write('Class Rest\\n')   # Title, optional\n",
    "\n",
    "            # List to store diagnosis group (either 0 or 1) for later group permutation\n",
    "            eb_list = []\n",
    "            for subj in df_qdec.itertuples():\n",
    "                subj_ptid = subj.fsid\n",
    "                # Select only subjects in the cluster we are selecting\n",
    "                # For all the subjects with the two diagnosis, assign them to class if they\n",
    "                # are included in the cluster, and to Rest if not.\n",
    "                if d[0] == subj.diagnosis:\n",
    "                    eb_list.append(0)\n",
    "                    if c == 'C' + str(int(subj.cluster)):\n",
    "                        cluster = d[0]\n",
    "                    else:\n",
    "                        cluster = 'Rest'\n",
    "                elif d[1] == subj.diagnosis:\n",
    "                    eb_list.append(1)\n",
    "                    if c == 'C' + str(int(subj.cluster)):\n",
    "                        cluster = d[1]\n",
    "                    else:\n",
    "                        cluster = 'Rest'\n",
    "                else:\n",
    "                    continue\n",
    "                f.write('Input ' + subj_ptid + ' ' + cluster + '\\n')\n",
    "\n",
    "            # NEED TO ALSO CREATE EB FILE\n",
    "            eb_out = 'freefiles/adni_files_ex2_' + c + '_' + d[0] + '_' + d[1] + '.csv'\n",
    "            with open(eb_out, 'w') as out:\n",
    "                for n in eb_list:\n",
    "                    out.write(str(n) + '\\n')\n",
    "                    \n",
    "# We will have a contrast file with 3 columns. Last one is 0!\n",
    "mtx = 'freefiles/ex2.mtx'\n",
    "contrast = \"+1 -1 0\\n\"\n",
    "write_contrast(mtx, contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run mri-prepoc with the selected subjects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_files/lh_thickness.adni_files_ex2_C1_CN_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C1_CN_AD.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C2_CN_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C2_CN_AD.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C3_CN_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C3_CN_AD.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C4_CN_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C4_CN_AD.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C1_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C1_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C2_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C2_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C3_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C3_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C4_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C4_CN_LMCI.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C1_LMCI_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C1_LMCI_AD.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C2_LMCI_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C2_LMCI_AD.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C3_LMCI_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C3_LMCI_AD.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex2_C4_LMCI_AD.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex2_C4_LMCI_AD.10.mgh Already exists!\n"
     ]
    }
   ],
   "source": [
    "# For each experiment, run mri-preproc to prepare for the experiments.\n",
    "# config variables:\n",
    "\n",
    "# fsgd files contain all the experiments already, so only one loop is needed\n",
    "# also, need to do lh and rh hemisferes\n",
    "hemis = [\"lh\", \"rh\"]\n",
    "for f in fsgd_files:\n",
    "    name = os.path.splitext(os.path.basename(f))[0]\n",
    "    for h in hemis:\n",
    "        # build the command\n",
    "        cmdline = [\"mris_preproc\", '--fsgd', f]\n",
    "        # fwhm10 hard coded! (TODO: maybe don't hardcode this?)\n",
    "        cmdline += ['--cache-in', mode + '.fwhm10.fsaverage']\n",
    "        cmdline += ['--target', 'fsaverage']\n",
    "        cmdline += ['--hemi', h]\n",
    "        cmdline += ['--out', \"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh\"]\n",
    "        # If out file exists, no need to run it again!\n",
    "        if os.path.exists(\"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh\"):\n",
    "            print(\"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh Already exists!\")\n",
    "            continue\n",
    "        else:\n",
    "            # Run the experiment\n",
    "            os.system(' '.join(cmdline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**run mri-glmfit and correct for multiple comparisons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, no need to do another loop\n",
    "hemis = [\"lh\", \"rh\"]\n",
    "for f in fsgd_files:\n",
    "    name = os.path.splitext(os.path.basename(f))[0]\n",
    "    for h in hemis:\n",
    "        # build the command\n",
    "        cmdline = [\"mri_glmfit\"]\n",
    "        cmdline += ['--y', \"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh\"]\n",
    "        cmdline += ['--fsgd', f, 'dods']\n",
    "        cmdline += ['--C', mtx]\n",
    "        cmdline += ['--surf', 'fsaverage', h]\n",
    "        cmdline += ['--cortex']\n",
    "        cmdline += ['--glmdir', \"glm_output/\" + h + \"_\" + name + \".glmdir\"]\n",
    "        # Needed for later correction\n",
    "        cmdline += ['--eres-save']\n",
    "        \n",
    "        # Run the experiment\n",
    "        os.system(' '.join(cmdline))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN PALM FOR MULTIPLE COMPARISONS\n",
    "## Correction for multiple comparisons\n",
    "hemis = [\"lh\", \"rh\"]\n",
    "for f in fsgd_files:\n",
    "    name = os.path.splitext(os.path.basename(f))[0]\n",
    "    for h in hemis:\n",
    "        # build the command\n",
    "        cmdline = [\"fspalm\"]\n",
    "        cmdline += ['--glmdir', \"glm_output/\" + h + \"_\" + name + \".glmdir\"]\n",
    "        cmdline += ['--cft', '1.3']\n",
    "        cmdline += ['--twotail']\n",
    "        cmdline += ['--name', 'palm_' + h + \"_\" + name]\n",
    "        cmdline += ['--iters', '1000']\n",
    "        cmdline += ['--2spaces']\n",
    "        cmdline += ['--cwp', '.05']\n",
    "        cmdline += ['--pargs=\"' + 'eb=freefiles/' + name + '.csv\"']\n",
    "\n",
    "        os.system(' '.join(cmdline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
