{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cortical structure experiments - 4\n",
    "\n",
    "This script performs permutation testing experiments on cortical structures for each cluster group with respect to the rest.\n",
    "\n",
    "This script generates the necessary files to run the freesurfer glmfit -sim command, with permutation testing, and save the results, for later analysis and visualization.\n",
    "\n",
    "More info about the permutation procedure in freesurfer can be found in:\n",
    "https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/MultipleComparisonsV6.0Perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization and loading of variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the procedure\n",
    "clusters = 4\n",
    "rd_seed = 1714\n",
    "n_perm = 1000\n",
    "\n",
    "# thickness or volume\n",
    "mode = \"thickness\"\n",
    "DX = ['CN', 'LMCI', 'AD']\n",
    "C = [\"C1\", \"C2\", \"C3\", \"C4\"]\n",
    "\n",
    "# Path of the generated clusters, after a run of cimlr-ad.py\n",
    "cluster_path = \"/homedtic/gmarti/EXPERIMENTS/CIMLR-AD/cimlr4/\"      \n",
    "df_cluster = pd.read_csv(cluster_path + 'cluster_data.csv')\n",
    "df_cluster.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare files for the concrete problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of subjects\n",
    "fsid_names = [x for x in map(lambda s: 'ADNI' + s[0:3] + 'S' + s[6:], \n",
    "                             df_cluster.PTID.values)]\n",
    "\n",
    "# Support dataframe, with the info that we need to write\n",
    "df_qdec = pd.DataFrame(data={'fsid': fsid_names,\n",
    "                            'cluster': df_cluster.C.values,\n",
    "                            'diagnosis': df_cluster.DX.values},\n",
    "                       columns = ['fsid', 'cluster', 'diagnosis'])\n",
    "\n",
    "# We want to test the thickness in the population of each cluster\n",
    "# against the rest, so that we can observe differences across the \n",
    "# whole cluster.\n",
    "\n",
    "# Create a fsgd file for each of the tests. In total, we have 12 experiments\n",
    "# (one for each cluster)\n",
    "fsgd_files = []\n",
    "for d in DX:\n",
    "    for c in C:\n",
    "        # Create FSGD file\n",
    "        # Only write the subjects that \n",
    "        fsgd_file = 'freefiles/adni_files_ex4_' + d + '_' + c + '.fsgd'\n",
    "        fsgd_files.append(fsgd_file)\n",
    "        with open(fsgd_file, 'w') as f:\n",
    "            f.write('GroupDescriptorFile 1\\n')  # First line, mandatory\n",
    "            f.write('Title CIMLR-AD ex4-' + d + '_' + c + 'vs Rest\\n')   # Title, optional\n",
    "            # only two classes: either the cluster class, or rest\n",
    "            f.write('Class ' + c + '\\n')   # Title, optional\n",
    "            f.write('Class Rest\\n')   # Title, optional\n",
    "            for subj in df_qdec.itertuples():\n",
    "                subj_ptid = subj.fsid\n",
    "                # Select only subjects in the cluster we are selecting\n",
    "                if subj.diagnosis != d:\n",
    "                    continue\n",
    "                if c == 'C' + str(int(subj.cluster)):\n",
    "                    cluster = 'C' + str(int(subj.cluster))\n",
    "                else:\n",
    "                    cluster = 'Rest'\n",
    "                f.write('Input ' + subj_ptid + ' ' + cluster + '\\n')\n",
    "\n",
    "# Contrast: same for all the 12 experiments\n",
    "def write_contrast(name, matrix):\n",
    "    with open(name, 'w') as f:\n",
    "        f.write(matrix)  # First line, mandatory\n",
    "\n",
    "# Mtx is actually the same for all subjects, as we are only comparing\n",
    "# two groups\n",
    "mtx = 'freefiles/ex4.mtx'\n",
    "contrast = \"+1 -1\\n\"\n",
    "write_contrast(mtx, contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run mri-prepoc with the selected subjects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_files/lh_thickness.adni_files_ex4_CN_C1.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_CN_C1.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_CN_C2.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_CN_C2.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_CN_C3.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_CN_C3.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_CN_C4.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_CN_C4.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_LMCI_C1.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_LMCI_C1.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_LMCI_C2.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_LMCI_C2.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_LMCI_C3.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_LMCI_C3.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_LMCI_C4.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_LMCI_C4.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_AD_C1.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_AD_C1.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_AD_C2.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_AD_C2.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_AD_C3.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_AD_C3.10.mgh Already exists!\n",
      "processed_files/lh_thickness.adni_files_ex4_AD_C4.10.mgh Already exists!\n",
      "processed_files/rh_thickness.adni_files_ex4_AD_C4.10.mgh Already exists!\n"
     ]
    }
   ],
   "source": [
    "# For each experiment, run mri-preproc to prepare for the experiments.\n",
    "# config variables:\n",
    "\n",
    "\n",
    "# also, need to do lh and rh hemisferes\n",
    "hemis = [\"lh\", \"rh\"]\n",
    "for f in fsgd_files:\n",
    "    name = os.path.splitext(os.path.basename(f))[0]\n",
    "    for h in hemis:\n",
    "        # build the command\n",
    "        cmdline = [\"mris_preproc\", '--fsgd', f]\n",
    "        # fwhm10 hard coded! (TODO: maybe don't hardcode this?)\n",
    "        cmdline += ['--cache-in', mode + '.fwhm10.fsaverage']\n",
    "        cmdline += ['--target', 'fsaverage']\n",
    "        cmdline += ['--hemi', h]\n",
    "        cmdline += ['--out', \"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh\"]\n",
    "        # If out file exists, no need to run it again!\n",
    "        if os.path.exists(\"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh\"):\n",
    "            print(\"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh Already exists!\")\n",
    "            continue\n",
    "        else:\n",
    "            # Run the experiment\n",
    "            os.system(' '.join(cmdline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**run mri-glmfit and correct for multiple comparisons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemis = [\"lh\", \"rh\"]\n",
    "for f in fsgd_files:\n",
    "    name = os.path.splitext(os.path.basename(f))[0]\n",
    "    for h in hemis:\n",
    "        # build the command\n",
    "        cmdline = [\"mri_glmfit\"]\n",
    "        cmdline += ['--y', \"processed_files/\" + h + \"_\" + mode + \".\" + name + \".10.mgh\"]\n",
    "        cmdline += ['--fsgd', f, 'dods']\n",
    "        cmdline += ['--C', mtx]\n",
    "        cmdline += ['--surf', 'fsaverage', h]\n",
    "        cmdline += ['--cortex']\n",
    "        cmdline += ['--glmdir', \"glm_output/\" + h + \"_\" + name + \".glmdir\"]\n",
    "        # Needed for later correction\n",
    "        cmdline += ['--eres-save']\n",
    "        \n",
    "        # Run the experiment\n",
    "        os.system(' '.join(cmdline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fsgd_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ac21070eef9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Correction for multiple comparisons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhemis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"lh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rh\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfsgd_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhemis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fsgd_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Correction for multiple comparisons\n",
    "hemis = [\"lh\", \"rh\"]\n",
    "for f in fsgd_files:\n",
    "    name = os.path.splitext(os.path.basename(f))[0]\n",
    "    for h in hemis:\n",
    "        # build the command\n",
    "        cmdline = [\"mri_glmfit-sim\"]\n",
    "        cmdline += ['--glmdir', \"glm_output/\" + h + \"_\" + name + \".glmdir\"]\n",
    "        # HARDCODED\n",
    "        # info about parameters: \n",
    "        # 1000 is number of permutations\n",
    "        # 4 is the range for clusters (in the surface)\n",
    "        # abs is to take into account both + and - diff\n",
    "        # (as we have no null hyp about either, we keep them both)\n",
    "        cmdline += ['--perm', '1000', '1.3', 'abs']\n",
    "        # clusters with <0.05 will be highlighted\n",
    "        cmdline += ['--cwp', '0.05']\n",
    "        # Correct for both hemispheres with Bonferroni\n",
    "        cmdline += ['--2spaces']\n",
    "        # Run in parallel (4 nodes)\n",
    "        cmdline += ['--bg', '4']\n",
    "        # Run the experiment\n",
    "        os.system(' '.join(cmdline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of experiments:12\n",
      "glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/\n",
      "# Cluster Growing Summary (mri_surfcluster)\n",
      "\n",
      "# $Id: mri_surfcluster.c,v 1.57.2.3 2016/11/17 18:19:42 zkaufman Exp $\n",
      "\n",
      "# $Id: mrisurf.c,v 1.781.2.6 2016/12/27 16:47:14 zkaufman Exp $\n",
      "\n",
      "# CreationTime 2018/10/16-17:05:55-GMT\n",
      "\n",
      "# cmdline mri_surfcluster.bin --in glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/sig.mgh --mask glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/mask.mgh --cwsig glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.cluster.mgh --sum glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.cluster.summary --ocn glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.ocn.mgh --annot aparc --cwpvalthresh 0.05 --o glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.masked.mgh --no-fixmni --csd glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/csd/perm.th13.abs.j001-ex4.csd --csd glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/csd/perm.th13.abs.j002-ex4.csd --csd glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/csd/perm.th13.abs.j003-ex4.csd --csd glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/csd/perm.th13.abs.j004-ex4.csd --csdpdf glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.pdf.dat --vwsig glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.voxel.mgh --vwsigmax glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.voxel.max.dat --oannot glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.ocn.annot --bonferroni 2 --surf white \n",
      "\n",
      "# cwd /homedtic/gmarti/CODE/simlr-ad/cortical_experiments\n",
      "\n",
      "# sysname  Linux\n",
      "\n",
      "# hostname node011\n",
      "\n",
      "# machine  x86_64\n",
      "\n",
      "# FixVertexAreaFlag 1\n",
      "\n",
      "# FixSurfClusterArea 1\n",
      "\n",
      "# \n",
      "\n",
      "# Input      glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/sig.mgh\n",
      "\n",
      "# Frame Number      0\n",
      "\n",
      "# srcsubj fsaverage\n",
      "\n",
      "# hemi lh\n",
      "\n",
      "# surface white\n",
      "\n",
      "# group_avg_surface_area 82220\n",
      "\n",
      "# group_avg_vtxarea_loaded 1\n",
      "\n",
      "# annot aparc\n",
      "\n",
      "# SUBJECTS_DIR /homedtic/gmarti/DATA/Data/SIMLR-AD-FS_Full/\n",
      "\n",
      "# SearchSpace_mm2 74707\n",
      "\n",
      "# SearchSpace_vtx 145321\n",
      "\n",
      "# Bonferroni 2\n",
      "\n",
      "# Minimum Threshold 1.3\n",
      "\n",
      "# Maximum Threshold infinity\n",
      "\n",
      "# Threshold Sign    abs\n",
      "\n",
      "# AdjustThreshWhenOneTail 1\n",
      "\n",
      "# CW PValue Threshold: 0.05 \n",
      "\n",
      "# Area Threshold    0 mm^2\n",
      "\n",
      "# CSD thresh  1.300000\n",
      "\n",
      "# CSD nreps    1000\n",
      "\n",
      "# CSD simtype  perm\n",
      "\n",
      "# CSD contrast ex4\n",
      "\n",
      "# CSD confint  90.000000\n",
      "\n",
      "# Overall max 6.2496 at vertex 24493\n",
      "\n",
      "# Overall min -1.02825 at vertex 132053\n",
      "\n",
      "# NClusters          2\n",
      "\n",
      "# FixMNI = 0\n",
      "\n",
      "# \n",
      "\n",
      "# ClusterNo  Max   VtxMax   Size(mm^2)  MNIX   MNIY   MNIZ    CWP    CWPLow    CWPHi   NVtxs    WghtVtx   Annot\n",
      "\n",
      "   1        6.250   24493   8596.31    -34.9   -9.7   53.8  0.00798  0.00400  0.01395  19566    44804.35  precentral\n",
      "\n",
      "   2        4.787   77175   3273.18    -37.3   51.1   -1.5  0.03371  0.02386  0.04352   4721    10369.67  rostralmiddlefrontal\n",
      "\n",
      "freeview --f $SUBJECTS_DIR/fsaverage/surf/lh.inflated:overlay=glm_output/lh_adni_files_ex4_LMCI_C4.glmdir/ex4/perm.th13.abs.sig.ocn.mgh:overlay_threshold=1.3:annot=aparc.annot:annot_outline=1 -viewport 3d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the results\n",
    "# lh or rh\n",
    "h = 'lh'\n",
    "# Number of experiments (max is len(fsgd_files))\n",
    "print('number of experiments:' + str(len(fsgd_files)))\n",
    "fsgd_number = 7\n",
    "name = os.path.splitext(os.path.basename(fsgd_files[fsgd_number]))[0]\n",
    "directory = \"glm_output/\" + h + \"_\" + name + \".glmdir/\"\n",
    "print(directory)\n",
    "\n",
    "# path to the glm-fit-sim output\n",
    "cluster_name = 'ex4/perm.th13.abs.sig.ocn.mgh'\n",
    "annot_name = 'ex4/perm.th13.abs.sig.ocn.annot'\n",
    "\n",
    "cmdline = 'freeview --f $SUBJECTS_DIR/fsaverage/surf/' + h +\\\n",
    "          '.inflated:overlay=' + directory + cluster_name + ':overlay_threshold=1.3:annot=' +\\\n",
    "          'aparc.annot:annot_outline=1 -viewport 3d'\n",
    "\n",
    "# Also, print resume file of clusters to have extra information\n",
    "resume_file = directory + 'ex4/perm.th13.abs.sig.cluster.summary'\n",
    "with open(resume_file, 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "\n",
    "        \n",
    "print(cmdline)\n",
    "os.system(cmdline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
